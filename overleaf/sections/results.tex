A métrica para cálculo de desempenho dos modelos durante a competição no \emph{Kaggle} foi a acurácia, e o melhor resultado obtido na competição foi de 71.16\%. Os resultados de acurácia e \emph{F1 Micro} para os modelos de CNN testados, bem como \emph{Ensemble} obtiveram os mesmos valores, visto isso é apresentado somente o valor da medida \emph{F1 Score Micro}. Na Tabela \ref{tbl:fscore} observa-se os resultados para cada modelo de CNN, juntamente do resultado do \emph{Ensemble}.

\input{tables/tbl_fscore.tex}

É observado que o melhor classificador, modelo 7, individual de CNN, obteve 69.49\% enquanto que o pior, modelo 9, obteve 62.44\%. Ressaltando que cada classificador de CNN usado no \emph{Ensemble} obteve resultados melhores do que os outros, em determinada expressão ou bons resultados em todas as expressões, mas não se sobressaiu em nenhuma expressão específica. No caso do modelo 9, obteve-se bons resultados em quase todas as expressões, mas nenhum resultado melhor na classificação de determinada expressão em relação aos outros modelos. Já no caso do modelo 7, obteve-se o melhor resultado de classificação para expressão de surpresa.

No modelo \textit{Ensemble} teve-se um total de 32.738.871 parâmetros treináveis, que é resultado da soma dos parâmetros treináveis dos modelos CNN, bem como do XGBoost. Onde o modelo de XGBoost possui uma quantidade pequena de parâmetros treináveis, em comparação com os modelos de CNN, pois, enquanto a quantidade deste está na ordem de milhares, os outros estão na ordem de milhões. Este comportamento se mostra coerente, se for levado em consideração as tarefas de cada modelo, que possuem complexidades bastante distintas.

Os modelos de CNN mais profundos, consequentemente com maior número de parâmetros treináveis, foram os que obtiveram melhores desempenho individuais. Já os modelos mais rasos, apesar de obterem desempenho abaixo dos profundos, obtiveram os melhores resultados em classificar expressões específicas. Quantidade de parâmetros treináveis do \textit{Ensemble} podem ser visualizados na Tabela \cite{tbl:param}.

\input{tables/tbl_param.tex}

Na Figura \ref{fig:emsemble} é apresentado o resultado do modelo utilizando \emph{Ensemble}. Onde o resultado final de desempenho foi de 71.74\% de acordo com a métrica \emph{F1 Micro}, ressaltando que seu valor de Acurácia possui o mesmo valor. E com este resultado o \emph{Ensemble} supera, por pouco, o modelo campeão da competição.

\begin{figure}[!htb]
    \centering
    \includegraphics[width=8cm]{images/cm_emsemble.png}
    \caption{Matriz de Confusão do \emph{Ensemble} (CNN + \emph{XGBoost})}
    \label{fig:emsemble}
\end{figure}
