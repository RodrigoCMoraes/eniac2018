{
  "cells": [
    {
      "metadata": {
        "_cell_guid": "417ed4a0-607c-4edc-8868-f4f348a7b39d",
        "_uuid": "7418086108306615f3ac551beea727cf2d46126f",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "from keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom keras.models import Sequential, load_model\nfrom keras.layers import Input, BatchNormalization, Activation, GlobalAveragePooling2D, UpSampling2D\nfrom keras.layers.core import Flatten, Dense, Dropout\nfrom keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D, AveragePooling2D\nfrom keras import backend as K\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, fbeta_score\n\nimport seaborn as sns\n\nimport pandas as pd\nimport numpy as np\nimport cv2\nfrom matplotlib import pyplot as plt\n\ndef prepare_dataset(dataframe, image_size={'width':48, 'height':48}):\n    faces_images = []\n    pixels = dataframe['pixels'].tolist()\n    for pixel_sequence in pixels:\n        face = [int(pixel) for pixel in pixel_sequence.split(' ')]\n        face = np.asarray(face).reshape(image_size['width'], image_size['height'])\n        face = cv2.resize(face.astype('uint8'), (image_size['width'], image_size['height']))        \n        faces_images.append(face.astype('float32') / 255.0)\n    faces_images = np.asarray(faces_images)\n    faces_images = np.expand_dims(faces_images, -1) # (1, 48, 48)\n    emotions_labels = pd.get_dummies(dataframe['emotion']).as_matrix()\n    return faces_images, emotions_labels\n  \ndef fbeta(y_true, y_pred, threshold_shift=0):\n    beta = 1\n\n    # just in case of hipster activation at the final layer\n    y_pred = K.clip(y_pred, 0, 1)\n\n    # shifting the prediction threshold from .5 if needed\n    y_pred_bin = K.round(y_pred + threshold_shift)\n\n    tp = K.sum(K.round(y_true * y_pred_bin), axis=1) + K.epsilon()\n    fp = K.sum(K.round(K.clip(y_pred_bin - y_true, 0, 1)), axis=1)\n    fn = K.sum(K.round(K.clip(y_true - y_pred, 0, 1)), axis=1)\n\n    precision = tp / (tp + fp)\n    recall = tp / (tp + fn)\n\n    beta_squared = beta ** 2\n    return K.mean((beta_squared + 1) * (precision * recall) / (beta_squared * precision + recall + K.epsilon()))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "8e78cb00-c55a-4d8b-bb72-af70b1b713f0",
        "_uuid": "ba4c6acf9843298fa4b6be90af4799e0853ae430",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "dataset = pd.read_csv('../input/fer2013.csv')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79f02f71-4337-468a-8dcf-23654a104b72",
        "_uuid": "47f2ef3bd64bbf3a77e5db42df890854ab107126",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "emotions_labels_map = {'angry':0,\n                       'disgust':1, \n                       'fear':2, \n                       'happy':3, \n                       'sad':4, \n                       'surprise':5, \n                       'neutral':6}\n\ngroups = dataset.groupby('Usage')\n\n# get group - training\ntraining_data = groups.get_group('Training')\n\n# get groups on training split by emotion\ntraining_emotions = training_data.groupby('emotion')\n\n# get group - test\ntest_data = groups.get_group('PublicTest')\n\n# get groups on test split by emotion\ntest_emotions = test_data.groupby('emotion')\n\n# get group - validation\nvalidation_data = groups.get_group('PrivateTest')\n\n# get groups on validation split by emotion\nvalidation_emotions = validation_data.groupby('emotion')\n\n# prepare dataset to training, test and validate model\ntraining_faces, training_emotions = prepare_dataset(training_data)\ntest_faces, test_emotions = prepare_dataset(test_data)\nvalidation_faces, validation_emotions = prepare_dataset(validation_data)\n\n# get size dataset elements\nnum_samples, num_classes = training_emotions.shape\n\n# split and randomize data\nx_train_part1, x_train_part2, y_train_part1, y_train_part2 = train_test_split(training_faces, training_emotions, test_size=0.3, random_state=42)\nx_train, y_train = np.vstack((x_train_part1, x_train_part2)), np.vstack((y_train_part1, y_train_part2))\n\nx_test_part1, x_test_part2, y_test_part1, y_test_part2 = train_test_split(test_faces, test_emotions, test_size=0.3, random_state=42)\nx_test, y_test = np.vstack((x_test_part1, x_test_part2)), np.vstack((y_test_part1, y_test_part2))\n\nx_validation_part1, x_validation_part2, y_validation_part1, y_validation_part2 = train_test_split(validation_faces, validation_emotions, test_size=0.3, random_state=42)\nx_validation, y_validation = np.vstack((x_validation_part1, x_validation_part2)), np.vstack((y_validation_part1, y_validation_part2))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# create data augmention\ndata_generator = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\ndata_generator.fit(x_train)\ndata_generator.fit(x_test)\ndata_generator.fit(x_validation)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "778c63a1-6cbf-4afd-aa53-1e4f18b8f1ff",
        "_uuid": "33d8b9afbd22e2d05d9cca2abf3ba61895f642b7",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "patience = 50\nbatch_size = 86\nnum_epochs = 100\n\nearly_stop = EarlyStopping(monitor='val_acc', patience=patience, mode='max')\nreduce_lr = ReduceLROnPlateau('val_acc', factor=0.5, patience=(patience//4))\ncallbacks = [early_stop, reduce_lr]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "43ac0134-c517-4d80-bcb2-04f274363759",
        "_uuid": "ef1ded8bba7425e89703b1e084aa550f7d282996",
        "collapsed": true,
        "scrolled": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "model = Sequential()\nmodel.add(Convolution2D(64, (3, 3), kernel_initializer='he_normal', activation='relu', padding='same', input_shape=(48, 48, 1)))\nmodel.add(BatchNormalization())\nmodel.add(Convolution2D(64, (3, 3), kernel_initializer='he_normal', activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(2, 2))\nmodel.add(Dropout(0.5))\n\nmodel.add(Convolution2D(128, (3, 3), kernel_initializer='he_normal', activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Convolution2D(128, (3, 3), kernel_initializer='he_normal', activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(2, 2))\nmodel.add(Dropout(0.5))\n\nmodel.add(Convolution2D(256, (3, 3), kernel_initializer='he_normal', activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Convolution2D(256, (3, 3), kernel_initializer='he_normal', activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Convolution2D(256, (3, 3), kernel_initializer='he_normal', activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(2, 2))\nmodel.add(Dropout(0.5))\n\nmodel.add(Convolution2D(512, (3, 3), kernel_initializer='he_normal', activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Convolution2D(512, (3, 3), kernel_initializer='he_normal', activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Convolution2D(512, (3, 3), kernel_initializer='he_normal', activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(2, 2))\nmodel.add(Dropout(0.5))\n\nmodel.add(Convolution2D(512, (3, 3), kernel_initializer='he_normal', activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Convolution2D(512, (3, 3), kernel_initializer='he_normal', activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Convolution2D(512, (3, 3), kernel_initializer='he_normal', activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(2, 2))\nmodel.add(Dropout(0.5))\n\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(7, activation='softmax'))\n\nmodel.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=[fbeta, 'accuracy'])\nmodel.summary()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "0f95325b-987f-41ab-b721-3167583f6016",
        "_uuid": "3cdd3412c26c91acb023f266dc7b22da750201e6",
        "collapsed": true,
        "scrolled": false,
        "trusted": false
      },
      "cell_type": "code",
      "source": "%%time\nhistory = model.fit_generator(data_generator.flow(x_train, y_train, batch_size),\n                    steps_per_epoch=len(x_train) / batch_size,\n                    epochs=num_epochs, verbose=True, callbacks=callbacks,\n                    validation_data=(x_test, y_test))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "42137834-cf24-4a48-abeb-b72d123b2395",
        "_uuid": "c7fc6df6efbbaffc6f8a5ba36ba04a8f43948505",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "score = model.evaluate(x_validation, y_validation)\n\nprint('Test score:', score[0])\nprint('Test accuracy:', score[1])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "6753999c-9183-48bb-8797-57a544e43256",
        "_uuid": "ee08af48671616fd5cb05d0f5bee13a0491d7d8a",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "#  summarize history for accuracy\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\nplt.savefig('cnn_accuracy.png')\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "f32e0b0f-1d7c-49b4-add4-8d021ed1cde3",
        "_uuid": "b9dde32b7435b85b225c145a06d7c2eed79f9b42",
        "collapsed": true,
        "scrolled": false,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Plot a confusion matrix\nemotions_text = ['angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral']\n\ny_pred = model.predict_classes(x_validation)\ny_true = np.asarray([np.argmax(i) for i in y_validation])\n\ncm = confusion_matrix(y_true, y_pred)\ncm_normalised = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\nsns.set(font_scale=4.5) \nfig, ax = plt.subplots(figsize=(15,15))\nax = sns.heatmap(cm_normalised, annot=True, linewidths=2.5, square=True, linecolor=\"Green\", \n                    cmap=\"Greens\", yticklabels=emotions_text, xticklabels=emotions_text, vmin=0, vmax=np.max(cm_normalised), \n                    fmt=\".2f\", annot_kws={\"size\": 25})\nax.set(xlabel='Predicted label', ylabel='True label')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "80e16e9d-768d-4138-b4c1-39757cb38b07",
        "_uuid": "e910dcdb282639da8ada0c5ee1fa5bf71dc63925",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "beta=1.0\nscore = fbeta_score(y_true, y_pred, average='micro', beta=beta)\nprint(\"fbeta = {}, beta = {}\".format(score, beta))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "8447a7a7-ab20-4a45-b1da-b1ba0ac7d401",
        "_uuid": "2f5f14cb6daae4ec5a073084affcdf894ffbe4a7",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "model_json = model.to_json()\nwith open(\"arch_1.json\",\"w\") as json_file:\n     json_file.write(model_json)\nmodel.save('weights_1.h5')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "ba2ee036-d381-46a7-9681-de30d07b83f0",
        "_uuid": "84a5cdf36e30c8d9cc5fdf358bb8ebda45779488",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# A ESTRATEGIA EH VERIFICAR SE OS ARQUIVOS SALVOS NO CONSOLE PODEM SER SALVOS PARA DOWNLOAD\n!ls",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}